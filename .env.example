# ============================================================================
# LLM Council - Distributed Configuration (2-PC Setup)
# ============================================================================
# This template shows all available configuration options.
# Copy this file to .env and customize for your setup.
# ============================================================================

# ----------------------------------------------------------------------------
# CHAIRMAN CONFIGURATION (PC1)
# ----------------------------------------------------------------------------
# The Chairman LLM runs on a dedicated machine for synthesis only
# Set this to the IP address of PC1 where the Chairman Ollama instance runs
CHAIRMAN_IP=localhost
CHAIRMAN_PORT=11434
CHAIRMAN_MODEL=qwen2.5:1.5b

# ----------------------------------------------------------------------------
# COUNCIL CONFIGURATION (PC2)
# ----------------------------------------------------------------------------
# Council LLMs run on a separate machine for initial responses and peer review
# Set this to the IP address of PC2 where the Council Ollama instances run
COUNCIL_IP=localhost
COUNCIL_PORT=11434

# ----------------------------------------------------------------------------
# DEPLOYMENT EXAMPLES
# ----------------------------------------------------------------------------
# 
# Example 1: Both on same machine (development/testing)
#   CHAIRMAN_IP=localhost
#   COUNCIL_IP=localhost
#
# Example 2: Chairman on PC1 (192.168.1.20), Council on PC2 (192.168.1.13)
#   CHAIRMAN_IP=192.168.1.20
#   COUNCIL_IP=192.168.1.13
#
# Example 3: Using Docker network names
#   CHAIRMAN_IP=ollama-chairman
#   COUNCIL_IP=ollama-council
#
# ----------------------------------------------------------------------------
# NOTES
# ----------------------------------------------------------------------------
# - Make sure Ollama is running on both machines
# - Ensure firewall allows connections on port 11434
# - Models will be automatically pulled if not already present
# - For multi-machine setup, use actual IP addresses or hostnames
